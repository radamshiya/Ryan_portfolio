---
title: "How Machines Should Talk"
summary: "Creating a design system for conversations applicable to new zero-to-one products."
role: "Research & Strategy"
date: "2024â€“2025"
image: "/images/machines_talking.png"
featured: true
---

<div class="two-column">
<div class="column">

## Problem

Hiya saw a clear opportunity to explore AI voice agents. Voice calls are the core of our business, and generative AI presented a path to both solve existing customer problems in the voice channel and expand into adjacent problems we were not yet addressing.
<br><br>
This was a completely new space for the company. Not just in terms of new technology, but in understanding *how* AI voice agents should behave. The industry conversation was dominated by demos that optimized for sounding human or appearing impressive, often framed around concepts like the uncanny valley. What was missing was a grounded understanding of what businesses actually want AI agents to sound like, how they want those agents to represent them, and what people calling or using those systems actually value in real interactions.
<br><br>
We needed a durable framework that could guide design decisions as the technology rapidly evolved, rather than chasing short-term trends or surface-level feedback.

</div>
<div class="column">

## Outcomes

- Created a living conversational design system applicable across teams and products  
- Successfully launched two zero-to-one products conversational products, Hiya AI Phone and Hiya Voice Agents.
- Strong qualitative feedback on usability, trust, and engagement with AI voice experiences  
- Balanced regulatory requirements (such as call recording disclosures across locales) with positive user experience  
- Built internal confidence that we had the right combination of technologies to deliver the desired experience  
- Enabled teams to stay focused despite rapid changes in the underlying AI technology landscape  

</div>
</div>

## My Role

I led the overall strategy and research, framing why conversational design needed to prioritize real user needs over what demos well. I drove all research, synthesis, and decision-making around how AI voice agents should behave and how those principles should be applied across products.

## Approach

This work spanned a wide range of activities due to the rapidly evolving nature of the technology. We conducted ongoing technical exploration to evaluate available AI voice technologies, continuously testing their strengths, limitations, and changes over time. Because the landscape shifted quickly, this required repeated iteration rather than one-time evaluation.
<br><br>
I designed surveys and controlled laboratory studies to test different voices, accents, pacing, and latency configurations. In partnership with engineering and product interns working on translation services, we built test environments that allowed native speakers to evaluate multilingual voice interactions and translation quality.
<br><br>
We partnered twice with the University of Washington to run applied research on how people want to interact with AI systems. These collaborations included both behavioral research and speculative prototyping to explore future interaction models.
<br><br>
Beyond structured research, we developed interactive prototypes outside of our core products and, in some cases, deployed them into production to gather real-world feedback. This helped mitigate the artificiality of lab settings, where people often behave differently when they know they are interacting with AI.
<br><br>
We also conducted extensive secondary research, drawing from studies on human conversation, cognitive load, turn-taking, interruption, and information retention to better understand constraints like how much information can be communicated effectively during a voice interaction.

## Findings

- What matters most in AI voice interactions is not realism, but clarity, predictability, and trust  
- Latency and conversational flow have a greater impact on experience than accent or vocal personality  
- Users value agents that represent them appropriately over agents that attempt to sound human  
- Providing consistent conversational rules creates better experiences than optimizing each interaction independently  
- A strong design system allows teams to evaluate feedback in context, distinguish outliers from systemic issues, and resist reacting to every new technology shift  
